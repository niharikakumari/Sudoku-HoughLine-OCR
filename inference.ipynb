{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model =  keras.models.load_model(\"digit_recognizer_best_model.h5\")\n",
    "# reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 4.5728355e-16, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_image = cv2.imread('crop_img/crop_1.png')\n",
    "# plt.imshow(test_image)\n",
    "# test_image_resized = test_image.reshape(28,28,1)\n",
    "test_image = Image.open('crop_img/crop_69.png')\n",
    "test_image_resized = test_image.resize((28,28))\n",
    "\n",
    "test_image_resized.save('crop_img/crop_72_resized.png')\n",
    "test_image_resized_2 = cv2.imread('crop_img/crop_72_resized.png')\n",
    "test_image_resized_gray = cv2.cvtColor(test_image_resized_2,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(test_image_resized_gray,140,255,cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(thresh)\n",
    "# np_img_2 = np.asarray(test_image_resized)\n",
    "np_img_3 = thresh.reshape([-1,28, 28,1])\n",
    "reconstructed_model.predict(np_img_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-b5ed59210281>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp_img_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image_resized\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# plt.imshow(np_img_2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtest_image_resized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# np_img_3 = np_img_2.reshape([-1,28, 28,1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# reconstructed_model.predict(np_img_3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "test_image = cv2.imread('crop_img/crop_1.png')\n",
    "# plt.imshow(test_image)\n",
    "test_image_resized = test_image.resize((28,28))\n",
    "# plt.imshow(test_image_resized)\n",
    "np_img_2 = np.asarray(test_image_resized,dtype='float32')\n",
    "# plt.imshow(np_img_2)\n",
    "test_image_resized.shape\n",
    "# np_img_3 = np_img_2.reshape([-1,28, 28,1])\n",
    "# reconstructed_model.predict(np_img_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model =  keras.models.load_model(\"digit_recognizer_best_model.h5\")\n",
    "# old_input = reconstructed_model._layers.pop(0)\n",
    "newInput = keras.Input(batch_shape=(133,133,1),name = \"digits\")\n",
    "# newOutputs = reconstructed_model(newInput)\n",
    "# newModel = keras.Model(newInput, newOutputs)\n",
    "reconstructed_model._layers[0] = newInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ConvLayer3 (Conv2D)          (None, 20, 20, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "ConvLayer4 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "ConvLayer5 (Conv2D)          (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "ConvLayer6 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "ConvLayer7 (Conv2D)          (None, 2, 2, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "DenseLayer1 (Dense)          (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "DenseLayer2 (Dense)          (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "prediction_layer (Dense)     (None, 10)                1290      \n",
      "=================================================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'trainable_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-b4ee0e9c2ffb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreconstructed_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2370\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2371\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2372\u001b[1;33m                               print_fn=print_fn)\n\u001b[0m\u001b[0;32m   2373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[1;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mtrainable_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mtrainable_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[0mnon_trainable_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnon_trainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrainable_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1908\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0msub_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1910\u001b[1;33m             extra_variables=self._trainable_weights))\n\u001b[0m\u001b[0;32m   1911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\tracking\\layer_utils.py\u001b[0m in \u001b[0;36mgather_trainable_weights\u001b[1;34m(trainable, sub_layers, extra_variables)\u001b[0m\n\u001b[0;32m    176\u001b[0m   \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msub_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[0mweights\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m   trainable_extra_variables = [\n\u001b[0;32m    180\u001b[0m       v for v in extra_variables if v.trainable]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'trainable_weights'"
     ]
    }
   ],
   "source": [
    "reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
