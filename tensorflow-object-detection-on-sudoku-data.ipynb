{"cells":[{"metadata":{},"cell_type":"markdown","source":"# TF Object Detection on Custom Data\nIn this notebook we will train a TensorFlow Object Detection model with a (large) custom dataset. We will cover the following steps:  \n* Install TensorFlow and TF Object Detection API\n* Fetch a pre-trained model from the TensorFlow detection model zoo\n* Configure the model and run training with the custom dataset\n* Make predictions with the trained model\n\nNow, the TensorFlow Object Detection API is not for the faint of heart to get started on, but once a few tweaks are in place, it is mostly smooth sailing."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Install TF Object Detection API\nThe [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) is at the time of writing not compatible with TF2 , so we need to install TF1.14 first. This notebook produces quite a lot of local files, and to keep a tidy house any large files not required will be removed (`rm -fr`)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle/working","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/working\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\nHAVE_GPU = True # change according to environment\nif HAVE_GPU:\n    !pip install --user tensorflow-gpu==1.14 -q\nelse:\n    !pip install --user tensorflow==1.14 -q\n# never mind the `ERROR: tensorflow 2.1...` message below","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make sure we the required packages\n!pip install --user Cython -q\n!pip install --user contextlib2 -q\n!pip install --user pillow -q\n!pip install --user lxml -q\n!pip install --user matplotlib -q","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to install the `protoc` compiler. On windows, you can get [precompiled binaries here](https://github.com/protocolbuffers/protobuf/releases)."},{"metadata":{"trusted":true},"cell_type":"code","source":"!wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip -q\n!unzip -o protobuf.zip\n!rm protobuf.zip","execution_count":5,"outputs":[{"output_type":"stream","text":"wget: /opt/conda/lib/libuuid.so.1: no version information available (required by wget)\nArchive:  protobuf.zip\n   creating: include/\n   creating: include/google/\n   creating: include/google/protobuf/\n  inflating: include/google/protobuf/struct.proto  \n  inflating: include/google/protobuf/type.proto  \n  inflating: include/google/protobuf/descriptor.proto  \n  inflating: include/google/protobuf/api.proto  \n  inflating: include/google/protobuf/empty.proto  \n   creating: include/google/protobuf/compiler/\n  inflating: include/google/protobuf/compiler/plugin.proto  \n  inflating: include/google/protobuf/any.proto  \n  inflating: include/google/protobuf/field_mask.proto  \n  inflating: include/google/protobuf/wrappers.proto  \n  inflating: include/google/protobuf/timestamp.proto  \n  inflating: include/google/protobuf/duration.proto  \n  inflating: include/google/protobuf/source_context.proto  \n   creating: bin/\n  inflating: bin/protoc              \n  inflating: readme.txt              \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Time to fetch the Object Detection API.\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Move up one level to avoid kernel crash when cloning repositories with deep folder structure.\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd /kaggle\n!rm -fr models\n!git clone https://github.com/tensorflow/models.git\n!rm -fr models/.git","execution_count":6,"outputs":[{"output_type":"stream","text":"/kaggle\nCloning into 'models'...\nremote: Enumerating objects: 13, done.\u001b[K\nremote: Counting objects: 100% (13/13), done.\u001b[K\nremote: Compressing objects: 100% (12/12), done.\u001b[K\nremote: Total 50733 (delta 4), reused 10 (delta 1), pack-reused 50720\u001b[K\nReceiving objects: 100% (50733/50733), 568.66 MiB | 32.30 MiB/s, done.\nResolving deltas: 100% (34551/34551), done.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Then compile the protocol buffer messages needed by the API."},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile ProtoBuffers\n%cd models/research\n!../../working/bin/protoc object_detection/protos/*.proto --python_out=.","execution_count":7,"outputs":[{"output_type":"stream","text":"/kaggle/models/research\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\nos.environ['AUTOGRAPH_VERBOSITY'] = '0'\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONPATH']=os.environ['PYTHONPATH']+':/kaggle/models/research/slim:/kaggle/models/research'\nos.environ['PYTHONPATH']","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"'/kaggle/lib/kagglegym:/kaggle/lib:/kaggle/models/research/slim:/kaggle/models/research'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tf_slim","execution_count":9,"outputs":[{"output_type":"stream","text":"Collecting tf_slim\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n\u001b[K     |████████████████████████████████| 358kB 894kB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from tf_slim) (0.8.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from absl-py>=0.2.2->tf_slim) (1.13.0)\nInstalling collected packages: tf-slim\nSuccessfully installed tf-slim-1.1.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"That's it! We can now test our setup by running `model_builder_test.py`."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd\n!python object_detection/builders/model_builder_test.py","execution_count":10,"outputs":[{"output_type":"stream","text":"/kaggle/models/research\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Yohoo, it works!  \nNow, we did not install the Coco API, since we will be using the Pascal VOC evaluation metric. Unfortunately, there are some hardcoded references to the Coco API that needs to be commented out. Alternatively, just install the Coco API."},{"metadata":{"trusted":true},"cell_type":"code","source":"def disable_coco(file):\n    with open(file,'r') as f:\n        file_str = f.read()\n    file_str=file_str.replace('from object_detection.metrics import coco_evaluation',\n                    '#from object_detection.metrics import coco_evaluation')\n    file_str=file_str.replace('object_detection.metrics import coco_tools',\n                    '#object_detection.metrics import coco_tools')\n    file_str=file_str.replace('\\'coco_detection_metrics\\':', '#\\'coco_detection_metrics\\':')\n    file_str=file_str.replace('coco_evaluation.CocoDetectionEvaluator,', '#coco_evaluation.CocoDetectionEvaluator,')\n    file_str=file_str.replace('\\'coco_mask_metrics\\':','#\\'coco_mask_metrics\\':')\n    file_str=file_str.replace('coco_evaluation.CocoMaskEvaluator,','#coco_evaluation.CocoMaskEvaluator,')\n    with open(file,'w') as f:\n        f.write(file_str)\n\ndisable_coco('./object_detection/eval_util.py')","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fetch a model from the zoo\nWe will start with a pre-trained model from [Tensorflow detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md). Our custom dataset is the [ArTaxOr dataset](https://www.kaggle.com/mistag/arthropod-taxonomy-orders-object-detection-dataset), which contains images of invertebrate animals. Thus it makes sense to choose one of the iNaturalist Species-trained model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd object_detection\n!wget -O faster_rcnn_resnet50_fgvc_2018_07_19.tar.gz http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_fgvc_2018_07_19.tar.gz -q\n!tar xvzf faster_rcnn_resnet50_fgvc_2018_07_19.tar.gz\n!rm faster_rcnn_resnet50_fgvc_2018_07_19.tar.gz\n%cd ..","execution_count":12,"outputs":[{"output_type":"stream","text":"/kaggle/models/research/object_detection\nwget: /opt/conda/lib/libuuid.so.1: no version information available (required by wget)\nfaster_rcnn_resnet50_fgvc_2018_07_19/model.ckpt.meta\nfaster_rcnn_resnet50_fgvc_2018_07_19/model.ckpt.index\nfaster_rcnn_resnet50_fgvc_2018_07_19/pipeline.config\nfaster_rcnn_resnet50_fgvc_2018_07_19/saved_model/\nfaster_rcnn_resnet50_fgvc_2018_07_19/checkpoint\nfaster_rcnn_resnet50_fgvc_2018_07_19/\nfaster_rcnn_resnet50_fgvc_2018_07_19/saved_model/saved_model.pb\nfaster_rcnn_resnet50_fgvc_2018_07_19/frozen_inference_graph.pb\nfaster_rcnn_resnet50_fgvc_2018_07_19/model.ckpt.data-00000-of-00001\nfaster_rcnn_resnet50_fgvc_2018_07_19/saved_model/variables/\n/kaggle/models/research\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Remove the <b>checkpoint</b> file, otherwise training will fail while loading graph.\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm object_detection/faster_rcnn_resnet50_fgvc_2018_07_19/checkpoint","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Furthermore, create a directory for saved models (otherwise an error will occur when training is finished)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd object_detection/faster_rcnn_resnet50_fgvc_2018_07_19\n!mkdir export\n%cd export\n!mkdir Servo\n%cd ../../..","execution_count":14,"outputs":[{"output_type":"stream","text":"/kaggle/models/research/object_detection/faster_rcnn_resnet50_fgvc_2018_07_19\n/kaggle/models/research/object_detection/faster_rcnn_resnet50_fgvc_2018_07_19/export\n/kaggle/models/research\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## **Time to create tf-records**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nwith open('/kaggle/input/sudokuimagesannotations/sudoku_annot_2.json', \"r\") as read_file:\n    data = json.load(read_file)\n    \npath = \"/kaggle/input/sudokuscreenshots/sudoku_imgs/\"\nkeys_list = list(data['_via_img_metadata'].keys())\njson_list = []\nfor key in keys_list:\n    i= keys_list.index(key)\n    val = data['_via_img_metadata'][key]['regions'][0]['shape_attributes']\n    key = key[:-6]\n    temp_image = cv2.imread(path + str(key))\n    value = (key,temp_image.shape[0],temp_image.shape[1],'Sudoku',val['x'],val['y'], val['x'] + val['width'], val['y'] + val['height'])\n    json_list.append(value)\n    \ncolumn_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\njson_df = pd.DataFrame(json_list, columns=column_name)\n\n# json_df.head()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ../../\n%cd working/\n!mkdir prog_outputs/\n%cd prog_outputs\n\njson_df.to_csv('/kaggle/working/prog_outputs/sudoku_labels.csv', index=False)\njson_df.head()","execution_count":16,"outputs":[{"output_type":"stream","text":"/kaggle\n/kaggle/working\n/kaggle/working/prog_outputs\n","name":"stdout"},{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"                                            filename  width  height   class  \\\n0  Screenshot_2021-01-07-23-19-00-858_com.easybra...   2280    1080  Sudoku   \n1  Screenshot_2021-01-07-23-19-21-187_com.easybra...   2280    1080  Sudoku   \n2  Screenshot_2021-01-07-23-19-37-128_com.easybra...   2280    1080  Sudoku   \n3  Screenshot_2021-01-07-23-19-52-081_com.easybra...   2280    1080  Sudoku   \n4  Screenshot_2021-01-07-23-20-03-976_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n0     8   306  1059  1369  \n1     5   299  1062  1365  \n2    19   323  1066  1366  \n3    13   306  1076  1373  \n4    17   310  1068  1369  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>width</th>\n      <th>height</th>\n      <th>class</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Screenshot_2021-01-07-23-19-00-858_com.easybra...</td>\n      <td>2280</td>\n      <td>1080</td>\n      <td>Sudoku</td>\n      <td>8</td>\n      <td>306</td>\n      <td>1059</td>\n      <td>1369</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Screenshot_2021-01-07-23-19-21-187_com.easybra...</td>\n      <td>2280</td>\n      <td>1080</td>\n      <td>Sudoku</td>\n      <td>5</td>\n      <td>299</td>\n      <td>1062</td>\n      <td>1365</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Screenshot_2021-01-07-23-19-37-128_com.easybra...</td>\n      <td>2280</td>\n      <td>1080</td>\n      <td>Sudoku</td>\n      <td>19</td>\n      <td>323</td>\n      <td>1066</td>\n      <td>1366</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Screenshot_2021-01-07-23-19-52-081_com.easybra...</td>\n      <td>2280</td>\n      <td>1080</td>\n      <td>Sudoku</td>\n      <td>13</td>\n      <td>306</td>\n      <td>1076</td>\n      <td>1373</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Screenshot_2021-01-07-23-20-03-976_com.easybra...</td>\n      <td>2280</td>\n      <td>1080</td>\n      <td>Sudoku</td>\n      <td>17</td>\n      <td>310</td>\n      <td>1068</td>\n      <td>1369</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir temp/\n%cd temp\n!cp -r '/kaggle/input/sudokuscreenshots/sudoku_imgs/' ./","execution_count":17,"outputs":[{"output_type":"stream","text":"/kaggle/working/prog_outputs/temp\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#not rescaling it now, as labelling has already been done\n\n# from PIL import Image\n# import os\n\n# def rescale_images(directory, size):\n#     for img in os.listdir(directory):\n#         im = Image.open(directory+img)\n#         im_resized = im.resize(size, Image.ANTIALIAS)\n#         im_resized.save(directory+img)\n\n# size = (512,512)\n# rescale_images ('/kaggle/working/prog_outputs/temp/sudoku_imgs/', size)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from os import listdir\nimport random\nfrom os.path import isfile, join\nmypath = '/kaggle/working/prog_outputs/temp/sudoku_imgs/'\nonlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\nrandom.shuffle(onlyfiles)\n\ntrain_imgs = onlyfiles[:70]\ntest_imgs = onlyfiles[70:86]\nprint(len(train_imgs))\nprint(len(test_imgs))","execution_count":19,"outputs":[{"output_type":"stream","text":"70\n16\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ..\n!mkdir train_imgs/\n!mkdir test_imgs/\n\n\nfrom shutil import copyfile, copy2\ndirectory = '/kaggle/working/prog_outputs/temp/sudoku_imgs/'\nfor img in os.listdir(directory):\n    source = directory + img\n    if img in train_imgs:\n        copy2(source, 'train_imgs/')\n    elif img in test_imgs:\n        copy2(source, 'test_imgs/' )","execution_count":20,"outputs":[{"output_type":"stream","text":"/kaggle/working/prog_outputs\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = json_df\ntest_labels = json_df\nfor index, row in json_df.iterrows():\n    if row['filename'] in train_imgs:\n        test_labels = test_labels.drop(index)\n    elif row['filename'] in test_imgs:\n        train_labels = train_labels.drop(index)\n\nprint(len(train_labels))\nprint(len(test_labels))\n\ntest_labels = test_labels.reset_index()\ntest_labels = test_labels.drop('index', axis = 1)\ntest_labels.to_csv('test_labels.csv',index=False)\n\ntrain_labels = train_labels.reset_index()\ntrain_labels = train_labels.drop('index', axis = 1)\ntrain_labels.to_csv('train_labels.csv',index=False)","execution_count":21,"outputs":[{"output_type":"stream","text":"70\n16\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"after running till here I am in this folder  /kaggle/working/prog_outputs, I should be in Kaggle/"},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ../../\n%cd models/research/","execution_count":22,"outputs":[{"output_type":"stream","text":"/kaggle\n/kaggle/models/research\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nUsage:\n  # From tensorflow/models/\n  # Create train data:\n  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record\n  # Create test data:\n  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record\n\"\"\"\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport os\nimport io\nimport pandas as pd\nimport tensorflow as tf\n\nfrom PIL import Image\nfrom object_detection.utils import dataset_util\nfrom collections import namedtuple, OrderedDict\n\n# flags = tf.app.flags\n# flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n# flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n# flags.DEFINE_string('image_dir', '', 'Path to images')\n# FLAGS = flags.FLAGS\n\n\n# TO-DO replace this with label map\ndef class_text_to_int(row_label):\n    if row_label == 'Sudoku':\n        return 1\n    else:\n        None\n\n\ndef split(df, group):\n    data = namedtuple('data', ['filename', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\n\ndef create_tf_example(group, path):\n    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    width, height = image.size\n\n    filename = group.filename.encode('utf8')\n    image_format = b'jpg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    for index, row in group.object.iterrows():\n        xmins.append(row['xmin'] / width)\n        xmaxs.append(row['xmax'] / width)\n        ymins.append(row['ymin'] / height)\n        ymaxs.append(row['ymax'] / height)\n        classes_text.append(row['class'].encode('utf8'))\n        classes.append(class_text_to_int(row['class']))\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image/height': dataset_util.int64_feature(height),\n        'image/width': dataset_util.int64_feature(width),\n        'image/filename': dataset_util.bytes_feature(filename),\n        'image/source_id': dataset_util.bytes_feature(filename),\n        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n        'image/format': dataset_util.bytes_feature(image_format),\n        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n        'image/object/class/label': dataset_util.int64_list_feature(classes),\n    }))\n    return tf_example\n\n\ndef main(csv_input, output_path,image_dir):\n    writer = tf.python_io.TFRecordWriter(output_path)\n#     path = os.path.join(image_dir)\n    print(path)\n    examples = pd.read_csv(csv_input)\n    grouped = split(examples, 'filename')\n    for group in grouped:\n#         print(group)\n        tf_example = create_tf_example(group, path)\n        writer.write(tf_example.SerializeToString())\n\n    writer.close()\n    output_path = os.path.join(os.getcwd(), output_path)\n    print('Successfully created the TFRecords: {}'.format(output_path))\n\n\n# if __name__ == '__main__':\n#     tf.app.run()","execution_count":23,"outputs":[{"output_type":"stream","text":"/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/root/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/root/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd ../../\n%cd working/prog_outputs/\n!mkdir tf-records/\n%cd ../../","execution_count":26,"outputs":[{"output_type":"stream","text":"/kaggle/working/prog_outputs\n/kaggle\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_output_path = 'working/prog_outputs/tf-records/train.record'\ntrain_csv_input = 'working/prog_outputs/train_labels.csv'\ntrain_image_dir = 'working/prog_outputs/train_imgs/'\n\ntest_output_path = 'working/prog_outputs/tf-records/test.record'\ntest_csv_input = 'working/prog_outputs/test_labels.csv'\ntest_image_dir = 'working/prog_outputs/test_imgs/'\n\nmain(train_csv_input, train_output_path, train_image_dir)\nmain(test_csv_input, test_output_path, test_image_dir)","execution_count":27,"outputs":[{"output_type":"stream","text":"working/prog_outputs/train_imgs/\ndata(filename='Screenshot_2021-01-07-23-19-00-858_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n0  Screenshot_2021-01-07-23-19-00-858_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n0     8   306  1059  1369  )\ndata(filename='Screenshot_2021-01-07-23-19-37-128_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n1  Screenshot_2021-01-07-23-19-37-128_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n1    19   323  1066  1366  )\ndata(filename='Screenshot_2021-01-07-23-19-52-081_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n2  Screenshot_2021-01-07-23-19-52-081_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n2    13   306  1076  1373  )\ndata(filename='Screenshot_2021-01-07-23-20-18-538_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n3  Screenshot_2021-01-07-23-20-18-538_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n3    21   306  1068  1361  )\ndata(filename='Screenshot_2021-01-07-23-20-44-162_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n4  Screenshot_2021-01-07-23-20-44-162_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n4    17   306  1068  1369  )\ndata(filename='Screenshot_2021-01-07-23-20-49-580_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n5  Screenshot_2021-01-07-23-20-49-580_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n5    13   306  1072  1369  )\ndata(filename='Screenshot_2021-01-07-23-20-54-170_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n6  Screenshot_2021-01-07-23-20-54-170_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n6     8   306  1067  1378  )\ndata(filename='Screenshot_2021-01-07-23-21-00-811_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n7  Screenshot_2021-01-07-23-21-00-811_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n7     8   310  1067  1373  )\ndata(filename='Screenshot_2021-01-07-23-21-08-789_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n8  Screenshot_2021-01-07-23-21-08-789_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n8     8   306  1075  1365  )\ndata(filename='Screenshot_2021-01-07-23-21-14-015_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n9  Screenshot_2021-01-07-23-21-14-015_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n9    17   310  1059  1369  )\ndata(filename='Screenshot_2021-01-07-23-21-25-773_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n10  Screenshot_2021-01-07-23-21-25-773_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n10    13   297  1076  1369  )\ndata(filename='Screenshot_2021-01-07-23-21-36-305_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n11  Screenshot_2021-01-07-23-21-36-305_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n11     4   306  1067  1373  )\ndata(filename='Screenshot_2021-01-07-23-21-42-129_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n12  Screenshot_2021-01-07-23-21-42-129_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n12    13   306  1068  1369  )\ndata(filename='Screenshot_2021-01-07-23-21-47-142_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n13  Screenshot_2021-01-07-23-21-47-142_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n13    13   314  1064  1361  )\ndata(filename='Screenshot_2021-01-07-23-21-52-227_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n14  Screenshot_2021-01-07-23-21-52-227_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n14    13   301  1072  1360  )\ndata(filename='Screenshot_2021-01-07-23-21-57-036_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n15  Screenshot_2021-01-07-23-21-57-036_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n15    21   306  1072  1365  )\ndata(filename='Screenshot_2021-01-07-23-22-01-969_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n16  Screenshot_2021-01-07-23-22-01-969_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n16    17   306  1064  1361  )\ndata(filename='Screenshot_2021-01-07-23-22-06-780_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n17  Screenshot_2021-01-07-23-22-06-780_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n17    17   301  1076  1360  )\ndata(filename='Screenshot_2021-01-07-23-22-20-821_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n18  Screenshot_2021-01-07-23-22-20-821_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n18     4   306  1067  1369  )\ndata(filename='Screenshot_2021-01-07-23-22-25-358_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n19  Screenshot_2021-01-07-23-22-25-358_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n19    13   301  1064  1377  )\ndata(filename='Screenshot_2021-01-07-23-22-30-239_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n20  Screenshot_2021-01-07-23-22-30-239_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n20     8   301  1067  1360  )\ndata(filename='Screenshot_2021-01-07-23-22-34-972_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n21  Screenshot_2021-01-07-23-22-34-972_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n21    13   301  1076  1360  )\ndata(filename='Screenshot_2021-01-07-23-22-39-460_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n22  Screenshot_2021-01-07-23-22-39-460_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n22     8   306  1071  1365  )\ndata(filename='Screenshot_2021-01-07-23-22-44-062_com.easybrain.sudoku.android.jpg', object=                                             filename  width  height   class  \\\n23  Screenshot_2021-01-07-23-22-44-062_com.easybra...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n23    21   306  1063  1369  )\ndata(filename='Screenshot_2021-01-07-23-24-38-270_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n24  Screenshot_2021-01-07-23-24-38-270_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n24    29   473  1055  1499  )\ndata(filename='Screenshot_2021-01-07-23-24-45-097_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n25  Screenshot_2021-01-07-23-24-45-097_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n25    29   486  1046  1495  )\ndata(filename='Screenshot_2021-01-07-23-24-49-587_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n26  Screenshot_2021-01-07-23-24-49-587_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n26    38   473  1055  1503  )\ndata(filename='Screenshot_2021-01-07-23-24-54-949_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n27  Screenshot_2021-01-07-23-24-54-949_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n27    21   473  1051  1507  )\ndata(filename='Screenshot_2021-01-07-23-25-00-711_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n28  Screenshot_2021-01-07-23-25-00-711_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n28    29   473  1046  1494  )\ndata(filename='Screenshot_2021-01-07-23-25-05-602_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n29  Screenshot_2021-01-07-23-25-05-602_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n29    25   477  1046  1494  )\ndata(filename='Screenshot_2021-01-07-23-25-19-438_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n30  Screenshot_2021-01-07-23-25-19-438_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n30    21   477  1047  1503  )\ndata(filename='Screenshot_2021-01-07-23-25-23-263_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n31  Screenshot_2021-01-07-23-25-23-263_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n31    25   465  1055  1503  )\ndata(filename='Screenshot_2021-01-07-23-25-26-916_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n32  Screenshot_2021-01-07-23-25-26-916_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n32    21   481  1055  1498  )\ndata(filename='Screenshot_2021-01-07-23-25-30-507_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n33  Screenshot_2021-01-07-23-25-30-507_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n33    33   473  1046  1499  )\ndata(filename='Screenshot_2021-01-07-23-25-37-383_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n34  Screenshot_2021-01-07-23-25-37-383_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n34    29   477  1059  1503  )\n","name":"stdout"},{"output_type":"stream","text":"data(filename='Screenshot_2021-01-07-23-25-40-803_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n35  Screenshot_2021-01-07-23-25-40-803_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n35    33   469  1050  1495  )\ndata(filename='Screenshot_2021-01-07-23-25-44-110_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n36  Screenshot_2021-01-07-23-25-44-110_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n36    25   465  1051  1495  )\ndata(filename='Screenshot_2021-01-07-23-25-47-434_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n37  Screenshot_2021-01-07-23-25-47-434_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n37    38   481  1047  1494  )\ndata(filename='Screenshot_2021-01-07-23-25-53-748_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n38  Screenshot_2021-01-07-23-25-53-748_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n38    38   481  1051  1498  )\ndata(filename='Screenshot_2021-01-07-23-25-56-957_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n39  Screenshot_2021-01-07-23-25-56-957_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n39    25   465  1042  1499  )\ndata(filename='Screenshot_2021-01-07-23-26-00-204_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n40  Screenshot_2021-01-07-23-26-00-204_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n40    33   473  1042  1494  )\ndata(filename='Screenshot_2021-01-07-23-26-06-952_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n41  Screenshot_2021-01-07-23-26-06-952_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n41    25   473  1042  1499  )\ndata(filename='Screenshot_2021-01-07-23-26-10-286_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n42  Screenshot_2021-01-07-23-26-10-286_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n42    38   477  1051  1494  )\ndata(filename='Screenshot_2021-01-07-23-26-14-288_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n43  Screenshot_2021-01-07-23-26-14-288_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n43    29   469  1046  1495  )\ndata(filename='Screenshot_2021-01-07-23-26-23-651_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n44  Screenshot_2021-01-07-23-26-23-651_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n44    33   477  1046  1503  )\ndata(filename='Screenshot_2021-01-07-23-26-26-845_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n45  Screenshot_2021-01-07-23-26-26-845_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n45    38   481  1047  1494  )\ndata(filename='Screenshot_2021-01-07-23-26-29-855_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n46  Screenshot_2021-01-07-23-26-29-855_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n46    42   477  1042  1498  )\ndata(filename='Screenshot_2021-01-07-23-26-32-782_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n47  Screenshot_2021-01-07-23-26-32-782_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n47    38   477  1043  1494  )\ndata(filename='Screenshot_2021-01-07-23-26-35-748_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n48  Screenshot_2021-01-07-23-26-35-748_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n48    29   473  1050  1494  )\ndata(filename='Screenshot_2021-01-07-23-26-38-550_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n49  Screenshot_2021-01-07-23-26-38-550_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n49    33   477  1050  1503  )\ndata(filename='Screenshot_2021-01-07-23-26-41-611_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n50  Screenshot_2021-01-07-23-26-41-611_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n50    21   473  1059  1503  )\ndata(filename='Screenshot_2021-01-07-23-27-00-441_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n51  Screenshot_2021-01-07-23-27-00-441_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n51    21   469  1055  1495  )\ndata(filename='Screenshot_2021-01-07-23-27-03-686_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n52  Screenshot_2021-01-07-23-27-03-686_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n52    29   477  1050  1494  )\ndata(filename='Screenshot_2021-01-07-23-28-11-994_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n53  Screenshot_2021-01-07-23-28-11-994_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n53    29   440  1042  1487  )\ndata(filename='Screenshot_2021-01-07-23-28-35-501_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n54  Screenshot_2021-01-07-23-28-35-501_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n54    29   448  1059  1478  )\ndata(filename='Screenshot_2021-01-07-23-28-43-382_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n55  Screenshot_2021-01-07-23-28-43-382_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n55    38   456  1047  1461  )\ndata(filename='Screenshot_2021-01-07-23-28-50-743_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n56  Screenshot_2021-01-07-23-28-50-743_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n56    29   448  1050  1478  )\ndata(filename='Screenshot_2021-01-07-23-28-57-843_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n57  Screenshot_2021-01-07-23-28-57-843_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n57    29   460  1059  1460  )\ndata(filename='Screenshot_2021-01-07-23-29-05-120_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n58  Screenshot_2021-01-07-23-29-05-120_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n58    38   448  1047  1478  )\ndata(filename='Screenshot_2021-01-07-23-29-18-613_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n59  Screenshot_2021-01-07-23-29-18-613_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n59    33   448  1042  1469  )\ndata(filename='Screenshot_2021-01-07-23-29-25-225_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n60  Screenshot_2021-01-07-23-29-25-225_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n60    29   440  1050  1482  )\ndata(filename='Screenshot_2021-01-07-23-29-33-250_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n61  Screenshot_2021-01-07-23-29-33-250_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n61    29   444  1059  1478  )\ndata(filename='Screenshot_2021-01-07-23-29-39-687_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n62  Screenshot_2021-01-07-23-29-39-687_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n62    25   444  1051  1478  )\ndata(filename='Screenshot_2021-01-07-23-29-46-453_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n63  Screenshot_2021-01-07-23-29-46-453_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n63    33   452  1054  1469  )\ndata(filename='Screenshot_2021-01-07-23-29-59-845_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n64  Screenshot_2021-01-07-23-29-59-845_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n64    29   440  1055  1470  )\ndata(filename='Screenshot_2021-01-07-23-30-06-359_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n65  Screenshot_2021-01-07-23-30-06-359_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n65    25   448  1051  1478  )\ndata(filename='Screenshot_2021-01-07-23-30-13-102_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n66  Screenshot_2021-01-07-23-30-13-102_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n66    29   456  1059  1482  )\ndata(filename='Screenshot_2021-01-07-23-30-20-139_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n67  Screenshot_2021-01-07-23-30-20-139_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n67    29   431  1050  1478  )\ndata(filename='Screenshot_2021-01-07-23-30-46-015_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n68  Screenshot_2021-01-07-23-30-46-015_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n68    29   452  1050  1473  )\ndata(filename='Screenshot_2021-01-07-23-30-52-555_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n69  Screenshot_2021-01-07-23-30-52-555_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n69    29   452  1050  1469  )\nSuccessfully created the TFRecords: /kaggle/working/prog_outputs/tf-records/train.record\nworking/prog_outputs/test_imgs/\ndata(filename='Screenshot_2021-01-07-23-19-21-187_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n0  Screenshot_2021-01-07-23-19-21-187_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n0     5   299  1062  1365  )\ndata(filename='Screenshot_2021-01-07-23-20-03-976_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n1  Screenshot_2021-01-07-23-20-03-976_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n1    17   310  1068  1369  )\ndata(filename='Screenshot_2021-01-07-23-20-37-885_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n2  Screenshot_2021-01-07-23-20-37-885_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n2    25   301  1076  1368  )\ndata(filename='Screenshot_2021-01-07-23-21-20-869_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n3  Screenshot_2021-01-07-23-21-20-869_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n3    13   306  1064  1365  )\n","name":"stdout"},{"output_type":"stream","text":"data(filename='Screenshot_2021-01-07-23-21-30-648_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n4  Screenshot_2021-01-07-23-21-30-648_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n4    13   306  1076  1369  )\ndata(filename='Screenshot_2021-01-07-23-22-49-206_com.easybrain.sudoku.android.jpg', object=                                            filename  width  height   class  \\\n5  Screenshot_2021-01-07-23-22-49-206_com.easybra...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n5     4   297  1071  1364  )\ndata(filename='Screenshot_2021-01-07-23-25-10-272_sudoku.puzzle.free.game.brain.jpg', object=                                            filename  width  height   class  \\\n6  Screenshot_2021-01-07-23-25-10-272_sudoku.puzz...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n6    29   473  1050  1494  )\ndata(filename='Screenshot_2021-01-07-23-25-34-357_sudoku.puzzle.free.game.brain.jpg', object=                                            filename  width  height   class  \\\n7  Screenshot_2021-01-07-23-25-34-357_sudoku.puzz...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n7    33   473  1042  1494  )\ndata(filename='Screenshot_2021-01-07-23-25-50-671_sudoku.puzzle.free.game.brain.jpg', object=                                            filename  width  height   class  \\\n8  Screenshot_2021-01-07-23-25-50-671_sudoku.puzz...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n8    29   469  1055  1495  )\ndata(filename='Screenshot_2021-01-07-23-26-17-587_sudoku.puzzle.free.game.brain.jpg', object=                                            filename  width  height   class  \\\n9  Screenshot_2021-01-07-23-26-17-587_sudoku.puzz...   2280    1080  Sudoku   \n\n   xmin  ymin  xmax  ymax  \n9    29   481  1050  1494  )\ndata(filename='Screenshot_2021-01-07-23-26-20-691_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n10  Screenshot_2021-01-07-23-26-20-691_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n10    33   486  1050  1503  )\ndata(filename='Screenshot_2021-01-07-23-27-07-240_sudoku.puzzle.free.game.brain.jpg', object=                                             filename  width  height   class  \\\n11  Screenshot_2021-01-07-23-27-07-240_sudoku.puzz...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n11    29   481  1046  1494  )\ndata(filename='Screenshot_2021-01-07-23-29-11-795_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n12  Screenshot_2021-01-07-23-29-11-795_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n12    33   452  1059  1469  )\ndata(filename='Screenshot_2021-01-07-23-29-53-114_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n13  Screenshot_2021-01-07-23-29-53-114_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n13    29   448  1046  1474  )\ndata(filename='Screenshot_2021-01-07-23-30-27-769_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n14  Screenshot_2021-01-07-23-30-27-769_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n14    38   448  1055  1478  )\ndata(filename='Screenshot_2021-01-07-23-30-35-882_easy.sudoku.puzzle.solver.free.jpg', object=                                             filename  width  height   class  \\\n15  Screenshot_2021-01-07-23-30-35-882_easy.sudoku...   2280    1080  Sudoku   \n\n    xmin  ymin  xmax  ymax  \n15    21   448  1055  1469  )\nSuccessfully created the TFRecords: /kaggle/working/prog_outputs/tf-records/test.record\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pwd","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"'/kaggle'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd working/prog_outputs/tf-records\n!ls -la\n%cd ../../../","execution_count":30,"outputs":[{"output_type":"stream","text":"/kaggle\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Create a label map .pbtxt file"},{"metadata":{"trusted":true},"cell_type":"code","source":"from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap, StringIntLabelMapItem\nfrom google.protobuf import text_format\n\n\ndef convert_classes(classes, start=1):\n    msg = StringIntLabelMap()\n    for id, name in enumerate(classes, start=start):\n        msg.item.append(StringIntLabelMapItem(id=id, name=name))\n\n    text = str(text_format.MessageToBytes(msg, as_utf8=True), 'utf-8')\n    return text\n\n\n\ntxt = convert_classes(['Sudoku'])\nprint(txt)\nwith open('working/prog_outputs/label_map.pbtxt', 'w') as f:\n    f.write(txt)","execution_count":31,"outputs":[{"output_type":"stream","text":"item {\n  name: \"Sudoku\"\n  id: 1\n}\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Config file\nThen we need to define the model `.config` file. Here we set up paths to the dataset and a few other parameters. Thankfully, TFRecords for the ArTaxOr dataset has been created in [this notebook](https://www.kaggle.com/mistag/tensorflow-tfrecords-demystified) so we can link directly to its output files. We will use a 80-20 split for training and evaluation, and since the dataset is sharded in 50 files, we can simply select 10 of them (arbitrary) to go into the evaluation set. We also need to determine how many images there are in the evaluation set to configure the evaluation stage correctly:"},{"metadata":{"trusted":true},"cell_type":"code","source":"%cd models/research/\n!ls -la","execution_count":33,"outputs":[{"output_type":"stream","text":"/kaggle/models/research\ntotal 104\ndrwxr-xr-x 24 root root 4096 Jan 21 17:40 .\ndrwxr-xr-x  7 root root 4096 Jan 21 17:39 ..\n-rw-r--r--  1 root root 7132 Jan 21 17:39 README.md\ndrwxr-xr-x  2 root root 4096 Jan 21 17:39 a3c_blogpost\ndrwxr-xr-x  3 root root 4096 Jan 21 17:39 adversarial_text\ndrwxr-xr-x  3 root root 4096 Jan 21 17:39 attention_ocr\ndrwxr-xr-x  4 root root 4096 Jan 21 17:39 audioset\ndrwxr-xr-x  2 root root 4096 Jan 21 17:39 autoaugment\ndrwxr-xr-x  4 root root 4096 Jan 21 17:39 cognitive_planning\ndrwxr-xr-x  7 root root 4096 Jan 21 17:39 cvt_text\ndrwxr-xr-x  3 root root 4096 Jan 21 17:39 deep_speech\ndrwxr-xr-x  9 root root 4096 Jan 21 17:39 deeplab\ndrwxr-xr-x  3 root root 4096 Jan 21 17:39 delf\ndrwxr-xr-x  8 root root 4096 Jan 21 17:39 efficient-hrl\ndrwxr-xr-x  3 root root 4096 Jan 21 17:39 lfads\ndrwxr-xr-x 13 root root 4096 Jan 21 17:39 lstm_object_detection\ndrwxr-xr-x  2 root root 4096 Jan 21 17:39 marco\ndrwxr-xr-x  2 root root 4096 Jan 21 17:39 nst_blogpost\ndrwxr-xr-x 29 root root 4096 Jan 21 17:39 object_detection\ndrwxr-xr-x  2 root root 4096 Jan 21 17:39 pcl_rl\ndrwxr-xr-x  2 root root 4096 Jan 21 17:39 rebar\ndrwxr-xr-x 11 root root 4096 Jan 21 17:39 seq_flow_lite\ndrwxr-xr-x  7 root root 4096 Jan 21 17:39 slim\ndrwxr-xr-x  2 root root 4096 Jan 21 17:40 tf-records\ndrwxr-xr-x  5 root root 4096 Jan 21 17:39 vid2depth\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\n#input_pattern='/kaggle/input/tensorflow-tfrecords-demystified/ArTaxOr-????1-of-00050.tfrecord;/kaggle/input/tensorflow-tfrecords-demystified/ArTaxOr-????7-of-00050.tfrecord'\n#input_files = tf.io.gfile.glob(input_pattern)\n# data_set = tf.data.TFRecordDataset('/kaggle/working/prog_outputs/tf-records/train.record')\n# records_n = sum(1 for record in data_set)\nrecords_n = 70 # takes a long time to run this, so cheating here\nprint(\"records_n = {}\".format(records_n))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\nos.environ['DATA_PATH']='/kaggle/working/prog_outputs/tf-records'       \nos.environ['MODEL_PATH']='object_detection/faster_rcnn_resnet50_fgvc_2018_07_19'","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile 'object_detection/faster_rcnn_resnet50_fgvc_2018_07_19/sudoku.config'\nmodel {\n  faster_rcnn {\n    num_classes: 1 # sudoku has 1 class currently\n    image_resizer {\n      keep_aspect_ratio_resizer {\n        min_dimension: 600\n        max_dimension: 1024\n      }\n    }\n    feature_extractor {\n      type: 'faster_rcnn_resnet50'\n      first_stage_features_stride: 16\n    }\n    first_stage_anchor_generator {\n      grid_anchor_generator {\n        scales: [0.25, 0.5, 1.0, 2.0]\n        aspect_ratios: [0.5, 1.0, 2.0]\n        height_stride: 16\n        width_stride: 16\n      }\n    }\n    first_stage_box_predictor_conv_hyperparams {\n      op: CONV\n      regularizer {\n        l2_regularizer {\n          weight: 0.0\n        }\n      }\n      initializer {\n        truncated_normal_initializer {\n          stddev: 0.01\n        }\n      }\n    }\n    first_stage_nms_score_threshold: 0.0\n    first_stage_nms_iou_threshold: 0.7\n    first_stage_max_proposals: 300\n    first_stage_localization_loss_weight: 2.0\n    first_stage_objectness_loss_weight: 1.0\n    initial_crop_size: 14\n    maxpool_kernel_size: 2\n    maxpool_stride: 2\n    second_stage_batch_size: 32\n    second_stage_box_predictor {\n      mask_rcnn_box_predictor {\n        use_dropout: false\n        dropout_keep_probability: 1.0\n        fc_hyperparams {\n          op: FC\n          regularizer {\n            l2_regularizer {\n              weight: 0.0\n            }\n          }\n          initializer {\n            variance_scaling_initializer {\n              factor: 1.0\n              uniform: true\n              mode: FAN_AVG\n            }\n          }\n        }\n      }\n    }\n    second_stage_post_processing {\n      batch_non_max_suppression {\n        score_threshold: 0.0\n        iou_threshold: 0.6\n        max_detections_per_class: 50\n        max_total_detections: 100\n      }\n      score_converter: SOFTMAX\n    }\n    second_stage_localization_loss_weight: 2.0\n    second_stage_classification_loss_weight: 1.0\n  }\n}\n\ntrain_config: {\n  batch_size: 1\n  num_steps: 4000000\n  optimizer {\n    momentum_optimizer: {\n      learning_rate: {\n        manual_step_learning_rate {\n          initial_learning_rate: 0.0002\n          schedule {\n            step: 20000\n            learning_rate: .00002\n          }\n          schedule {\n            step: 50000\n            learning_rate: .000002\n          }\n        }\n      }\n      momentum_optimizer_value: 0.9\n    }\n    use_moving_average: false\n  }\n  gradient_clipping_by_norm: 10.0\n  fine_tune_checkpoint: \"/kaggle/models/research/object_detection/faster_rcnn_resnet50_fgvc_2018_07_19/model.ckpt\"\n  from_detection_checkpoint: true\n  load_all_detection_checkpoint_vars: true\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n}\n\ntrain_input_reader: {\n  label_map_path: \"/kaggle/working/prog_outputs/label.pbtxt\"\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/prog_outputs/tf-records/train.record\"\n  }\n}\n\neval_config: {\n  metrics_set: \"pascal_voc_detection_metrics\"\n  #use_moving_averages: false\n  num_examples: records_n\n}\n\neval_input_reader: {\n  label_map_path: \"/kaggle/working/prog_outputs/label.pbtxt\"\n  shuffle: false\n  num_readers: 1\n  tf_record_input_reader {\n    input_path: \"/kaggle/working/prog_outputs/tf-records/test.record\"\n  }\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note! Tensorboard only works in editor mode (kernel running), so we will not be using it here.\n#%load_ext tensorboard\n#%tensorboard --logdir=object_detection/faster_rcnn_resnet50_fgvc_2018_07_19","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"20000 steps take about 2h to run. Training will output large amounts of text, and once things are working it is better to dump it to a file rather than having to scroll down past thousands of lines."},{"metadata":{"trusted":true},"cell_type":"code","source":"old_stdout = sys.stdout\nsys.stdout = open('/kaggle/working/train.log', 'w')\n!python object_detection/model_main.py \\\n    --pipeline_config_path=object_detection/faster_rcnn_resnet50_fgvc_2018_07_19/sudoku.config \\\n    --model_dir=object_detection/faster_rcnn_resnet50_fgvc_2018_07_19 \\\n    --num_train_steps=1000 \\\n    --sample_1_of_n_eval_examples=1 \\\n    --alsologtostderr=False\nsys.stdout = old_stdout","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Export the trained model to working directory using the supplied script."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture cap_out --no-stderr\n!mkdir /kaggle/working/trained\n!python object_detection/export_inference_graph.py \\\n    --input_type image_tensor \\\n    --pipeline_config_path object_detection/faster_rcnn_resnet50_fgvc_2018_07_19/sudoku.config \\\n    --trained_checkpoint_prefix object_detection/faster_rcnn_resnet50_fgvc_2018_07_19/model.ckpt-1000 \\\n    --output_directory /kaggle/working/trained","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -al /kaggle/working/trained","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Zip it for easy download."},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar -cvzf /kaggle/working/trained_model.tar /kaggle/working/trained\n!gzip /kaggle/working/trained_model.tar","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check precision vs. training steps by parsing data from the log file."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --user parse -q\nfrom parse import *\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nwith open('/kaggle/working/train.log', 'r') as f:\n    data=f.read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss=[]\nfor r in findall(\"Loss/RPNLoss/localization_loss = {:f}\", data):\n    loss.append(r[0])\nmAP=[]\nfor r in findall(\"/mAP@0.5IOU = {:f}\", data):\n    mAP.append(r[0])\nstep=[]\nfor r in findall(\"global_step = {:d}\", data):\n    step.append(r[0])\nplt.figure(figsize=(16, 8))\nplt.plot(step,mAP)\nplt.xlabel('Global step')\nplt.legend(['mAP@0.5IOU']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's have a look at precision for each class:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# APAraneae=[]\n# for r in findall(\"AP@0.5IOU/Araneae = {:f}\", data):\n#     APAraneae.append(r[0])\n# APColeoptera=[]\n# for r in findall(\"AP@0.5IOU/Coleoptera = {:f}\", data):\n#     APColeoptera.append(r[0])\n# APDiptera=[]\n# for r in findall(\"AP@0.5IOU/Diptera = {:f}\", data):\n#     APDiptera.append(r[0])\n# APHemiptera=[]\n# for r in findall(\"AP@0.5IOU/Hemiptera = {:f}\", data):\n#     APHemiptera.append(r[0])\n# APHymenoptera=[]\n# for r in findall(\"AP@0.5IOU/Hymenoptera = {:f}\", data):\n#     APHymenoptera.append(r[0])\n# APLepidoptera=[]\n# for r in findall(\"AP@0.5IOU/Lepidoptera = {:f}\", data):\n#     APLepidoptera.append(r[0])\n# APOdonata=[]\n# for r in findall(\"AP@0.5IOU/Odonata = {:f}\", data):\n#     APOdonata.append(r[0])\n# plt.figure(figsize=(16, 8))\n# plt.plot(step,APAraneae)\n# plt.plot(step,APColeoptera)\n# plt.plot(step,APDiptera)\n# plt.plot(step,APHemiptera)\n# plt.plot(step,APHymenoptera)\n# plt.plot(step,APLepidoptera)\n# plt.plot(step,APOdonata)\n# plt.xlabel('Global step')\n# plt.legend(['AP Araneae', 'AP Coleoptera', 'AP Diptera', 'AP Hemiptera', 'AP Hymenoptera', 'AP Lepidoptera', 'AP Odonata']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Odonata (dragonflies and damselflies) is the class with the highest score, while Hymenoptera (bees, wasps, ants) is the class the model struggles most with."},{"metadata":{},"cell_type":"markdown","source":"## Prediction (detections)\nThe easiest way to make predictions (or detections) with the trained model is to use the API supplied script `infer_detections.py`, which expects images in a TFRecord file. Note that this script is difficult on Windows machines. We will make predictions on the [ArTaxOr TestSet](https://www.kaggle.com/mistag/arthropod-taxonomy-orders-object-detection-testset). The [starter kernel](https://www.kaggle.com/mistag/starter-arthropod-taxonomy-orders-testset) outputs a TFRecord file, so we can simply link to that. The detections are output in a separate TFRecord file, which we will process further down."},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%capture cap_out --no-stderr\n# !python object_detection/inference/infer_detections.py \\\n#   --input_tfrecord_paths=/kaggle/input/starter-arthropod-taxonomy-orders-testset/test.record \\\n#   --output_tfrecord_path=/kaggle/working/ArTaxOr_detections.tfrecord \\\n#   --inference_graph=/kaggle/working/trained/frozen_inference_graph.pb \\\n#   --discard_image_pixels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !ls /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we'll import pickled annotation data from the [ArtAxOr TestSet Starter notebook](https://www.kaggle.com/mistag/starter-arthropod-taxonomy-orders-testset). Then we read in the TFRecord with the detections, and create a Pandas frame with the detected bounding boxes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# %%capture\n# import pandas as pd\n# import tensorflow as tf\n\n# labels=pd.read_pickle('/kaggle/input/starter-arthropod-taxonomy-orders-testset/testset_labels.pkl')\n# df=pd.read_pickle('/kaggle/input/starter-arthropod-taxonomy-orders-testset/testset_filelist.pkl')\n# anno=pd.read_pickle('/kaggle/input/starter-arthropod-taxonomy-orders-testset/testset_objects.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pdf=pd.DataFrame(columns=['score', 'label_idx', 'left', 'top', 'right', 'bottom', 'by', 'filename'])\n# example = tf.train.Example()\n# for record in tf.compat.v1.io.tf_record_iterator('/kaggle/working/ArTaxOr_detections.tfrecord'):\n#     example.ParseFromString(record)\n#     f = example.features.feature\n#     score = f['image/detection/score'].float_list.value\n#     score = [x for x in score if x >= 0.60]\n#     l = len(score)\n#     pdf=pdf.append({'score': score,\n#                     'label_idx': f['image/detection/label'].int64_list.value[:l],\n#                     'left': f['image/detection/bbox/xmin'].float_list.value[:l],\n#                     'top': f['image/detection/bbox/ymin'].float_list.value[:l],\n#                     'right': f['image/detection/bbox/xmax'].float_list.value[:l],\n#                     'bottom': f['image/detection/bbox/ymax'].float_list.value[:l],\n#                     'by': f['image/by'].bytes_list.value[0].decode(),\n#                     'filename': f['image/filename'].bytes_list.value[0].decode()}, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pdf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then we define a few helper functions for plotting the test images and bounding boxes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install --user python-resize-image -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from PIL import Image, ImageFont, ImageDraw\n# from resizeimage import resizeimage\n# import numpy as np\n\n# TSET_PATH = '/kaggle/input/arthropod-taxonomy-orders-object-detection-testset/ArTaxOr_TestSet/'\n\n# #fontname = 'C:/Windows/fonts/micross.ttf' # Windows\n# fontname = '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf' # Linux\n# font = ImageFont.truetype(fontname, 20) if os.path.isfile(fontname) else ImageFont.load_default()\n\n# def resize_image(file, width, height, stretch=False):\n#     with Image.open(file) as im:\n#         img = im.resize((width, height)) if stretch else resizeimage.resize_contain(im, [width, height])\n#     img=img.convert(\"RGB\")    \n#     return img\n\n# #draw boundary box\n# def bbox(img, xmin, ymin, xmax, ymax, color, width, label, score):\n#     draw = ImageDraw.Draw(img)\n#     xres, yres = img.size[0], img.size[1]\n#     box = np.multiply([xmin, ymin, xmax, ymax], [xres, yres, xres, yres]).astype(int).tolist()\n#     txt = \" {}: {}%\" if score >= 0. else \" {}\"\n#     txt = txt.format(label, round(score, 1))\n#     ts = draw.textsize(txt, font=font)\n#     draw.rectangle(box, outline=color, width=width)\n#     if len(label) > 0:\n#         if box[1] >= ts[1]+3:\n#             xsmin, ysmin = box[0], box[1]-ts[1]-3\n#             xsmax, ysmax = box[0]+ts[0]+2, box[1]\n#         else:\n#             xsmin, ysmin = box[0], box[3]\n#             xsmax, ysmax = box[0]+ts[0]+2, box[3]+ts[1]+1\n#         draw.rectangle([xsmin, ysmin, xsmax, ysmax], fill=color)\n#         draw.text((xsmin, ysmin), txt, font=font, fill='white')\n    \n# #prediction\n# def plot_img_pred(img, xres, yres, axes, scores, xmin, ymin, xmax, ymax, classes, title, by=''):\n#     wscale = min(1,xres/yres)\n#     hscale = min(1,yres/xres)\n#     for i in range(len(scores)):\n#         if scores[i]> 0.5 and classes[i]>0:\n#             label = labels.name.iloc[int(classes[i]-1)]\n#             color=labels.color.iloc[int(classes[i]-1)]\n#             width, height = xmax[i]-xmin[i], ymax[i]-ymin[i]\n#             xcenter, ycenter = xmin[i] + width/2., ymin[i] + height/2.\n#             sxmin = .5+(xcenter-.5)*wscale-.5*wscale*width\n#             symin = .5+(ycenter-.5)*hscale-.5*hscale*height\n#             sxmax = .5+(xcenter-.5)*wscale+.5*wscale*width\n#             symax = .5+(ycenter-.5)*hscale+.5*hscale*height\n#             bbox(img, sxmin, symin, sxmax, symax, color, 2, label, 100*scores[i])\n#     plt.setp(axes, xticks=[], yticks=[])\n#     axes.set_title(title) if by == '' else axes.set_title(title+'\\n'+by)\n#     plt.imshow(img)\n\n# #ground truth\n# def plot_img_gt(img, axes, boxes, stretch, title, by=''):\n#     wscale = 1. if stretch else min(1,boxes.xres.iloc[0]/boxes.yres.iloc[0])\n#     hscale = 1. if stretch else min(1,boxes.yres.iloc[0]/boxes.xres.iloc[0])\n#     for i in range(len(boxes)):\n#         label = boxes.label.iloc[i]\n#         color=labels.color.iloc[boxes.label_idx.iloc[i]]\n#         xmin = .5+(boxes.xcenter.iloc[i]-.5)*wscale-.5*wscale*boxes.width.iloc[i]\n#         ymin = .5+(boxes.ycenter.iloc[i]-.5)*hscale-.5*hscale*boxes.height.iloc[i]\n#         xmax = .5+(boxes.xcenter.iloc[i]-.5)*wscale+.5*wscale*boxes.width.iloc[i]\n#         ymax = .5+(boxes.ycenter.iloc[i]-.5)*hscale+.5*hscale*boxes.height.iloc[i]\n#         bbox(img, xmin, ymin, xmax, ymax, color, 2, label, -1)\n#     plt.setp(axes, xticks=[], yticks=[])\n#     axes.set_title(title) if by == '' else axes.set_title(title+'\\n'+by)\n#     plt.imshow(img)\n\n# def pred_batch(idx):\n#     if idx + 2 < len(pdf):\n#         rows = 3\n#     else:\n#         rows = len(pdf) - idx\n#     fig = plt.figure(figsize=(16,rows*8))\n#     for i in range(rows):\n#         img = resize_image(TSET_PATH+'positives/'+pdf.filename.iloc[i+idx], 512, 512, False)\n#         by = pdf.by.iloc[i+idx]\n#         axes = fig.add_subplot(rows, 2, 1+i*2)\n#         boxes = anno[anno.id == df.id.iloc[i+idx]][['label', 'label_idx', 'xres', 'yres', 'xcenter', 'ycenter', 'width', 'height']]\n#         plot_img_gt(img, axes, boxes, False, 'Ground truth', by)\n#         img = resize_image(TSET_PATH+'positives/'+pdf.filename.iloc[i+idx], 512, 512, False)\n#         axes = fig.add_subplot(rows, 2, 2+i*2)\n#         plot_img_pred(img, boxes.xres.iloc[0], boxes.yres.iloc[0], axes, pdf.score[i+idx], pdf.left[i+idx], pdf.top[i+idx], \n#                       pdf.right[i+idx], pdf.bottom[i+idx],\n#                       pdf.label_idx[i+idx], 'Detections', '')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally we can show some images, with ground truth to the left and detections to the right. Some detections are overlapping, and additional non-max suppression seems to be needed here."},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_batch(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_batch(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_batch(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_batch(9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_batch(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_batch(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_batch(18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Summary\nAny object detection framework that has all files located in a directory called `research` should ring a few alarm bells when it comes to expectations of a slick user experience. However, we have seen that a few tweaks are all that is needed to get going with the TensorFlow Object Detection API. What about other options for object detection? PyTorch Detectron2 is the only other framework that has a pretrained model zoo, but currently it does not run on Kaggle (and no Windows support). TensorFlow Hub has several pre-trained models, and otherwise one would have to engage in detail implementation of models like YOLO etc. What we really need is to get object detection from research level and into mainstream."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}